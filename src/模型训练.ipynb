{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "    \n",
    "# å‡†å¤‡æ•°æ®\n",
    "data_url = '../data/more_TTI_preprosess.csv' # æ„å»ºçš„å†å²TTIæ•°æ®ç‰¹å¾\n",
    "train_df = pd.read_csv(data_url, infer_datetime_format=True, parse_dates=['time'])\n",
    "data_url = '../data/gps_features_detailed.csv' # æ„å»ºçš„GPSæ•°æ®ç‰¹å¾\n",
    "gps_df = pd.read_csv(data_url, infer_datetime_format=True, parse_dates=['time'])\n",
    "train_df = train_df.merge(gps_df, how='left', left_on='time', right_on='time')\n",
    "train_df.fillna(0,inplace=True)\n",
    "# train_df = train_df[train_df['time'].apply(lambda t: t <= datetime.datetime.strptime('2019-12-20 23:59:59', \"%Y-%m-%d %H:%M:%S\"))]\n",
    "\n",
    "road_id = [276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "\n",
    "def find_festival(Datetime, how):\n",
    "    day_length = timedelta(days = 999)\n",
    "    if how=='last':# å¯»æ‰¾å‰ä¸€ä¸ªè·ç¦»æœ€è¿‘çš„èŠ‚å‡æ—¥\n",
    "        for days in holidays.keys():\n",
    "            if days <= Datetime.date() and Datetime.date()-days<day_length:\n",
    "                day_length = Datetime.date()-days\n",
    "                length = day_length.days\n",
    "                date = days\n",
    "    elif how=='next':# å¯»æ‰¾åä¸€ä¸ªè·ç¦»æœ€è¿‘çš„èŠ‚å‡æ—¥\n",
    "        for days in holidays.keys():\n",
    "            if days > Datetime.date() and days - Datetime.date()<day_length:\n",
    "                day_length = days - Datetime.date()\n",
    "                length = day_length.days\n",
    "                date = days\n",
    "    return length, holidays[date]\n",
    "\n",
    "# 1æœˆ1æ—¥å…ƒæ—¦ã€2æœˆ4æ—¥é™¤å¤•ã€2æœˆ5æ—¥-2æœˆ10æ—¥æ˜¥èŠ‚ã€2æœˆ11æ—¥å¼€å·¥æ—¥ã€2æœˆ19å…ƒå®µèŠ‚ã€10æœˆ1-7æ—¥å›½åº†èŠ‚\n",
    "# èŠ‚å‡æ—¥åŠå…¶å‡æœŸçš„å¤©æ•°\n",
    "holidays = {datetime.date(2018,12,30):3, datetime.date(2019,2,4):7, datetime.date(2019,10,1):7\n",
    "           ,datetime.date(2020,1,1):1, datetime.date(2020,1,17):7, datetime.date(2020,1,24):7, datetime.date(2020,4,4):3}\n",
    "\n",
    "\n",
    "Y_labels = ['TTI_0','TTI_1','TTI_2','recent'] # yçš„æ ‡ç­¾\n",
    "X_labels = ['last_festival', 'last_festival_days' ,'next_festival', 'next_festival_days']\n",
    "\n",
    "# åŠ å…¥å‘¨æœŸæ€§çš„ä¿¡æ¯å’ŒèŠ‚å‡æ—¥çš„ä¿¡æ¯\n",
    "train_df['month'] = train_df['time'].apply(lambda x:x.month)\n",
    "train_df['day'] = train_df['time'].apply(lambda x:x.day) # è¯¥æœˆä¸­çš„ç¬¬å‡ å¤©\n",
    "train_df['hour'] = train_df['time'].apply(lambda x:x.hour)\n",
    "train_df['minute'] = train_df['time'].apply(lambda x:x.minute)\n",
    "train_df['week'] = train_df['time'].apply(lambda x:x.dayofweek)\n",
    "train_df['weekday'] = train_df['time'].apply(lambda x:x.weekday())\n",
    "train_df['n_10'] = train_df['hour'] * 6 + train_df['minute'] // 10 + 1  #è®°å½•å½“å¤©ç¬¬å‡ ä¸ª10åˆ†é’Ÿ\n",
    "train_df['is_festival'] = train_df['time'].apply(lambda t: 0 if (t.date() not in holidays.keys()) else 1) #æ ‡ç¤ºï¼šæ˜¯å¦æ˜¯èŠ‚å‡æ—¥\n",
    "train_df['last_festival'] = train_df['time'].apply(lambda t: find_festival(t, how='last')[0]) #è·ç¦»å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "train_df['last_festival_days'] = train_df['time'].apply(lambda t: find_festival(t, how='last')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "train_df['next_festival'] = train_df['time'].apply(lambda t: find_festival(t, how='next')[0]) #è·ç¦»åä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "train_df['next_festival_days'] = train_df['time'].apply(lambda t: find_festival(t, how='next')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "\n",
    "to_predict_X_test = pd.read_csv('./to_predict_x_gps_detailed3.csv', infer_datetime_format=True, parse_dates=['time'])\n",
    "to_predict_X_test = to_predict_X_test[:84]\n",
    "to_predict_X_test.fillna(0,inplace=True)\n",
    "to_predict_X_test['month'] = to_predict_X_test['time'].apply(lambda x:x.month)\n",
    "to_predict_X_test['day'] = to_predict_X_test['time'].apply(lambda x:x.day) # è¯¥æœˆä¸­çš„ç¬¬å‡ å¤©\n",
    "to_predict_X_test['hour'] = to_predict_X_test['time'].apply(lambda x:x.hour)\n",
    "to_predict_X_test['minute'] = to_predict_X_test['time'].apply(lambda x:x.minute)\n",
    "to_predict_X_test['week'] = to_predict_X_test['time'].apply(lambda x:x.dayofweek)\n",
    "to_predict_X_test['weekday'] = to_predict_X_test['time'].apply(lambda x:x.weekday())\n",
    "to_predict_X_test['is_festival'] = to_predict_X_test['time'].apply(lambda t: 0 if (t.date() not in holidays.keys()) else 1) #æ ‡ç¤ºï¼šæ˜¯å¦æ˜¯èŠ‚å‡æ—¥\n",
    "to_predict_X_test['n_10'] = to_predict_X_test['hour'] * 6 + to_predict_X_test['minute'] // 10 + 1  #è®°å½•å½“å¤©ç¬¬å‡ ä¸ª10åˆ†é’Ÿ\n",
    "to_predict_X_test['last_festival'] = to_predict_X_test['time'].apply(lambda t: find_festival(t, how='last')[0]) #è·ç¦»å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X_test['last_festival_days'] = to_predict_X_test['time'].apply(lambda t: find_festival(t, how='last')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X_test['next_festival'] = to_predict_X_test['time'].apply(lambda t: find_festival(t, how='next')[0]) #è·ç¦»åä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X_test['next_festival_days'] = to_predict_X_test['time'].apply(lambda t: find_festival(t, how='next')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "\n",
    "\n",
    "to_predict_X = pd.read_csv('./to_predict_x_gps_detailed3_stage2.csv', infer_datetime_format=True, parse_dates=['time'])\n",
    "to_predict_X.fillna(0,inplace=True)\n",
    "to_predict_X['month'] = to_predict_X['time'].apply(lambda x:x.month)\n",
    "to_predict_X['day'] = to_predict_X['time'].apply(lambda x:x.day) # è¯¥æœˆä¸­çš„ç¬¬å‡ å¤©\n",
    "to_predict_X['hour'] = to_predict_X['time'].apply(lambda x:x.hour)\n",
    "to_predict_X['minute'] = to_predict_X['time'].apply(lambda x:x.minute)\n",
    "to_predict_X['week'] = to_predict_X['time'].apply(lambda x:x.dayofweek)\n",
    "to_predict_X['weekday'] = to_predict_X['time'].apply(lambda x:x.weekday())\n",
    "to_predict_X['is_festival'] = to_predict_X['time'].apply(lambda t: 0 if (t.date() not in holidays.keys()) else 1) #æ ‡ç¤ºï¼šæ˜¯å¦æ˜¯èŠ‚å‡æ—¥\n",
    "to_predict_X['n_10'] = to_predict_X['hour'] * 6 + to_predict_X['minute'] // 10 + 1  #è®°å½•å½“å¤©ç¬¬å‡ ä¸ª10åˆ†é’Ÿ\n",
    "to_predict_X['last_festival'] = to_predict_X['time'].apply(lambda t: find_festival(t, how='last')[0]) #è·ç¦»å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X['last_festival_days'] = to_predict_X['time'].apply(lambda t: find_festival(t, how='last')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X['next_festival'] = to_predict_X['time'].apply(lambda t: find_festival(t, how='next')[0]) #è·ç¦»åä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "to_predict_X['next_festival_days'] = to_predict_X['time'].apply(lambda t: find_festival(t, how='next')[1]) #å‰ä¸€ä¸ªèŠ‚å‡æ—¥å¤©æ•°\n",
    "\n",
    "known_21 = pd.read_csv('1221known.csv')['TTI']\n",
    "known_0101 = pd.read_csv('0101known.csv')['TTI']\n",
    "\n",
    "\n",
    "keypoints = [[114.01619, 22.59639],[114.02036, 22.58824],[114.03132, 22.59794],\n",
    "             [114.01962, 22.60689],[114.03029, 22.60736],[114.02983, 22.61313],\n",
    "             [114.03332, 22.60873],[114.02789, 22.60277],[114.02570, 22.60831],\n",
    "             [114.02594, 22.61078],[114.03243, 22.59199],[114.02634, 22.61345],\n",
    "             [114.033524, 22.605982],[114.01562, 22.59151],[114.02367, 22.58933],\n",
    "            [114.028857, 22.604546],[114.02996, 22.61016]]\n",
    "keydirections = [[[0,90],[180,270]],[[45,90],[225,270]],[[90,270],[270,90]],\n",
    "                [[0,90],[180,270]],[[0,90],[180,270]],[[0,90],[180,270]],\n",
    "                [[0,90],[180,270]],[[90,270],[270,90]],[[90,270],[270,90]],\n",
    "                [[0,90],[180,270]],[[0,180],[180,360]],[[90,270],[270,90]],\n",
    "                 [[90,180],[270,360]],[[0,90],[180,270]],[[45,90],[225,270]],\n",
    "                 [[0,90],[180,270]],[[90,180],[270,360]]]\n",
    "\n",
    "# å·®åˆ†ç‰¹å¾æ„å»º\n",
    "for rid in road_id:\n",
    "    for minutes in range(10,60,10):\n",
    "        train_df['speed{}_diff{}'.format(rid,minutes)] = train_df['speed_{}_{}'.format(rid,minutes)]-train_df['speed_{}_{}'.format(rid,minutes-10)]\n",
    "        train_df['tti{}_diff{}'.format(rid,minutes)] = train_df['tti_{}_{}'.format(rid,minutes)]-train_df['tti_{}_{}'.format(rid,minutes-10)]\n",
    "        to_predict_X['speed{}_diff{}'.format(rid,minutes)] = to_predict_X['speed_{}_{}'.format(rid,minutes)]-to_predict_X['speed_{}_{}'.format(rid,minutes-10)]\n",
    "        to_predict_X['tti{}_diff{}'.format(rid,minutes)] = to_predict_X['tti_{}_{}'.format(rid,minutes)]-to_predict_X['tti_{}_{}'.format(rid,minutes-10)]\n",
    "        to_predict_X_test['speed{}_diff{}'.format(rid,minutes)] = to_predict_X_test['speed_{}_{}'.format(rid,minutes)]-to_predict_X_test['speed_{}_{}'.format(rid,minutes-10)]\n",
    "        to_predict_X_test['tti{}_diff{}'.format(rid,minutes)] = to_predict_X_test['tti_{}_{}'.format(rid,minutes)]-to_predict_X_test['tti_{}_{}'.format(rid,minutes-10)]\n",
    "n_keypoints = len(keypoints)\n",
    "for minutes in range(10,60,10):\n",
    "    for i in range(n_keypoints):\n",
    "        for j in range(len(keydirections[i])):# æ¯ä¸ªè§‚æµ‹ç‚¹ä¸åŒçš„æ–¹å‘\n",
    "            for minutes in range(10, 60, 5):\n",
    "                train_df['point{}direction{}volume_diff{}'.format(i, j, minutes)] = train_df['point{}direction{}volume{}'.format(i, j, minutes)] - train_df['point{}direction{}volume{}'.format(i, j, minutes-5)]\n",
    "                train_df['point{}direction{}speedmean_diff{}'.format(i, j, minutes)] = train_df['point{}direction{}speedmean{}'.format(i, j, minutes)] - train_df['point{}direction{}speedmean{}'.format(i, j, minutes-5)]\n",
    "                to_predict_X['point{}direction{}volume_diff{}'.format(i, j, minutes)] = to_predict_X['point{}direction{}volume{}'.format(i, j, minutes)] - to_predict_X['point{}direction{}volume{}'.format(i, j, minutes-5)]\n",
    "                to_predict_X['point{}direction{}speedmean_diff{}'.format(i, j, minutes)] = to_predict_X['point{}direction{}speedmean{}'.format(i, j, minutes)] - to_predict_X['point{}direction{}speedmean{}'.format(i, j, minutes-5)]\n",
    "                to_predict_X_test['point{}direction{}volume_diff{}'.format(i, j, minutes)] = to_predict_X_test['point{}direction{}volume{}'.format(i, j, minutes)] - to_predict_X_test['point{}direction{}volume{}'.format(i, j, minutes-5)]\n",
    "                to_predict_X_test['point{}direction{}speedmean_diff{}'.format(i, j, minutes)] = to_predict_X_test['point{}direction{}speedmean{}'.format(i, j, minutes)] - to_predict_X_test['point{}direction{}speedmean{}'.format(i, j, minutes-5)]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_table = [\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "    [{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'},{'boosting_type': 'gbdt', 'max_depth': 30, 'n_estimators': 200, 'num_leaves': 50, 'objective': 'regression_l1'}],\n",
    "]\n",
    "\n",
    "\n",
    "related_table = [\n",
    "    [[276183, 276184, 275911, 275912, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,1,2,4,5,7,10,12,13,14,15]],\n",
    "    [[276183, 276184, 275911, 275912, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,1,2,4,5,7,10,12,13,14,15]],\n",
    "    [[276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276737, 276738]\n",
    "     ,[0,1,2,3,4,7,8,9,10,13,14,15]],\n",
    "    [[276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276737, 276738]\n",
    "     ,[0,1,2,3,4,7,8,9,10,13,14,15]],\n",
    "    [[275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,2,3,4,5,6,7,8,9,11,12,13,15,16]],\n",
    "    [[275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,2,3,4,5,6,7,8,9,11,12,13,15,16]],\n",
    "    [[276183, 276184, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]],\n",
    "    [[276183, 276184, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]],\n",
    "    [[276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[1,2,3,4,5,6,7,8,9,10,11,12,14,15,16]],\n",
    "    [[276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[1,2,3,4,5,6,7,8,9,10,11,12,14,15,16]],\n",
    "    [[276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]],\n",
    "    [[276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "     ,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_id = [276183, 276184, 275911, 275912, 276240, 276241, 276264, 276265, 276268, 276269, 276737, 276738]\n",
    "predictions = []\n",
    "predictions2 = []\n",
    "maes_1221 = []\n",
    "maes_0101 = []\n",
    "new_order = [2,3,0,1,4,5,6,7,8,9,10,11]\n",
    "for road_num in range(len(road_id)):\n",
    "    train_df_temp = train_df[(train_df['road_id'] == road_id[road_num]) & (train_df['n_10'] >= 45) & (train_df['n_10'] <= 121)]\n",
    "    # å¯ä»¥è°ƒæ•´çœ‹ä½¿ç”¨speedè¿˜æ˜¯TTIé¢„æµ‹\n",
    "    Y_labels = ['TTI_0','TTI_1','TTI_2','recent'] # yçš„æ ‡ç­¾\n",
    "    X_labels = ['last_festival', 'last_festival_days' ,'next_festival', 'next_festival_days', 'n_10']\n",
    "    for rid in related_table[road_num][0]:\n",
    "        for minutes in range(0,60,10):\n",
    "            X_labels.append('speed_{}_{}'.format(rid,minutes))\n",
    "#             X_labels.append('tti_{}_{}'.format(rid,minutes))\n",
    "\n",
    "    # åŠ å…¥GPSé‡‡æ ·ç‚¹çš„ç‰¹å¾ä¿¡æ¯\n",
    "    n_keypoints = len(keypoints)\n",
    "    for i in related_table[road_num][1]:\n",
    "        for j in range(len(keydirections[i])):# æ¯ä¸ªè§‚æµ‹ç‚¹ä¸åŒçš„æ–¹å‘\n",
    "            for minutes in range(0, 60, 5):\n",
    "                X_labels.append('point{}direction{}volume{}'.format(i, j, minutes))\n",
    "                X_labels.append('point{}direction{}speedmean{}'.format(i, j, minutes))\n",
    "    #             train_df['point{}direction{}speedmean{}'.format(i, j, minutes)].replace(0, 40, inplace=True)\n",
    "    #             to_predict_X['point{}direction{}speedmean{}'.format(i, j, minutes)].replace(0, 40, inplace=True)\n",
    "\n",
    "    # æ„å»ºå·®åˆ†ç‰¹å¾\n",
    "#     for rid in road_id:\n",
    "    rid = road_id[road_num]\n",
    "    for minutes in range(10,60,10):\n",
    "        X_labels.append('speed{}_diff{}'.format(rid,minutes))\n",
    "#         X_labels.append('tti{}_diff{}'.format(rid,minutes))\n",
    "        \n",
    "    # for i in range(n_keypoints):\n",
    "    #     for j in range(len(keydirections[i])):# æ¯ä¸ªè§‚æµ‹ç‚¹ä¸åŒçš„æ–¹å‘\n",
    "    #         for minutes in range(10, 60, 5):\n",
    "    #             X_labels.append('point{}direction{}volume_diff{}'.format(i, j, minutes))\n",
    "    #             X_labels.append('point{}direction{}speedmean_diff{}'.format(i, j, minutes))\n",
    "\n",
    "    X, Y = train_df_temp[X_labels],train_df_temp[Y_labels]\n",
    "    # å‚æ•°å¯ä»¥è°ƒboosting, objective\n",
    "    params = {\n",
    "    'boosting_type': 'gbdt', 'max_depth': 50, 'n_estimators': 200, 'num_leaves': 30, 'objective': 'regression_l1'}\n",
    "    \n",
    "    # åœ¨æ­¤å¤„å¯ä»¥ä¿®æ”¹ä½¿ç”¨å·®åˆ†é¢„æµ‹è¿˜æ˜¯éå·®åˆ†ï¼Œè¿˜éœ€è¦å°†ğŸ‘‡çš„y_prediction.append(y_10[i] + temp.iloc[i,2])çš„åŠ æ³•åˆ å»\n",
    "    data = lgb.Dataset(X, label=Y['TTI_0'])\n",
    "    lgb1s = lgb.train(parameter_table[road_num][0], data, feature_name=X_labels)\n",
    "\n",
    "    data = lgb.Dataset(X, label=Y['TTI_1'])\n",
    "    lgb2s = lgb.train(parameter_table[road_num][1], data, feature_name=X_labels)\n",
    "\n",
    "    data = lgb.Dataset(X, label=Y['TTI_2'])\n",
    "    lgb3s = lgb.train(parameter_table[road_num][2], data, feature_name=X_labels)\n",
    "#     print('road {} train MAE ='.format(road_id[road_num]), (mean_absolute_error(Y['TTI_0'], lgb1s.predict(X)) + mean_absolute_error(Y['TTI_1'], lgb2s.predict(X)) + mean_absolute_error(Y['TTI_2'], lgb3s.predict(X)))/3)\n",
    "\n",
    "\n",
    "    temp = to_predict_X[to_predict_X['road_id']==road_id[road_num]]\n",
    "    temp2 = to_predict_X_test[to_predict_X_test['road_id']==road_id[road_num]]\n",
    "    y_prediction = []\n",
    "    y_prediction2 = []\n",
    "    y_10 = lgb1s.predict(temp[X_labels])\n",
    "    y_20 = lgb2s.predict(temp[X_labels])\n",
    "    y_30 = lgb3s.predict(temp[X_labels])\n",
    "    y2_10 = lgb1s.predict(temp2[X_labels])\n",
    "    y2_20 = lgb2s.predict(temp2[X_labels])\n",
    "    y2_30 = lgb3s.predict(temp2[X_labels])\n",
    "    for i in range(len(y_10)):\n",
    "        y_prediction.append(y_10[i])\n",
    "        y_prediction.append(y_20[i])\n",
    "        y_prediction.append(y_30[i])\n",
    "    for i in range(len(y2_10)):\n",
    "        y_prediction2.append(y2_10[i])\n",
    "        y_prediction2.append(y2_20[i])\n",
    "        y_prediction2.append(y2_30[i])\n",
    "    \n",
    "    test_y = known_0101[list(range(21*road_num, 21*road_num+21))]\n",
    "    test_y2 = known_21[list(range(21*road_num, 21*road_num+21))]\n",
    "    mae = mean_absolute_error(test_y, y_prediction[:len(test_y)])\n",
    "    mae2 = mean_absolute_error(test_y2, y_prediction2[:len(test_y2)])\n",
    "    predictions.append(y_prediction)\n",
    "    predictions2.append(y_prediction2)\n",
    "    maes_0101.append(mae)\n",
    "    maes_1221.append(mae2)\n",
    "#     print('MAE in 01.01 =', mae)\n",
    "#     print('MAE in 12.21 =', mae2)\n",
    "print(np.mean(maes_0101))    \n",
    "print(np.mean(maes_1221))\n",
    "\n",
    "\n",
    "# è¾“å‡ºç»“æœåˆ°csv\n",
    "y_prediction = []\n",
    "for day in range(12):\n",
    "    for road_num in [2,3,0,1,4,5,6,7,8,9,10,11]:\n",
    "        y_prediction = y_prediction + predictions[road_num][day*21:(day+1)*21]\n",
    "csvFile = open(\"lgb_l1/lgb_speed_nodiff_l1.csv\", \"w\")\n",
    "writer = csv.writer(csvFile)\n",
    "writer.writerow([\"id_sample\", \"TTI\"])\n",
    "for i in range(len(y_prediction)):\n",
    "    writer.writerow([i, y_prediction[i]])\n",
    "csvFile.close()\n",
    "print(\"Finished prediction!\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
